{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN attack via ResNet using Skywater non-linearized data\n",
    "\n",
    "The goal of this notebook is to correctly preprocess the given data as tensors that can be used to train ResNet101."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader.py\n",
    "# Necessary imports\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dataloaders\n",
    "Used files from Kareem's GitHub repo. I may have made mistakes in sampling the data, so feel free to change anything that has been configured incorrectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader.py\n",
    "# Returns list of files with given format \n",
    "def get_files(directory, format, digital_index=0):\n",
    "\n",
    "    format = re.compile(format)\n",
    "    files = os.listdir(directory)\n",
    "\n",
    "    #file_dict = {}\n",
    "    file_list = [] # fname, fpath, label\n",
    "\n",
    "    for fname in files:\n",
    "        if match := format.match(fname):\n",
    "            fpath = os.path.join(directory, fname)\n",
    "\n",
    "            dvalue = int(match.groups()[digital_index])\n",
    "            \n",
    "            file_list.append((fname, fpath, dvalue))\n",
    "\n",
    "            #if dvalue in file_dict:\n",
    "            #    file_dict[dvalue].append(fpath)\n",
    "            #else:\n",
    "            #    file_dict[dvalue] = [fpath]\n",
    "\n",
    "    return file_list #file_dict, file_path\n",
    "\n",
    "# Creates dataset with given traces\n",
    "class TraceDataset(Dataset):\n",
    "    cached_traces = {}\n",
    "    trace_list    = []\n",
    "\n",
    "    def __init__(self, file_list, cache=True):\n",
    "        self.file_list = file_list\n",
    "        self.cache     = cache\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        fname, fpath, label = self.file_list[index]\n",
    "        label = self.process_label(label)\n",
    "\n",
    "        if self.cache and fname in self.cached_traces:\n",
    "            return self.cached_traces[fname], label\n",
    "        else:\n",
    "            return self.load_trace(fname, fpath), label\n",
    "\n",
    "    def get_info(self, index):\n",
    "        return self.file_list[index]\n",
    "\n",
    "    def load_trace(self, fname, fpath):\n",
    "        with open(fpath, 'r') as file:\n",
    "            header = file.readline()\n",
    "            #time_arr = []\n",
    "            valu_arr = []\n",
    "\n",
    "            for line in file.readlines():\n",
    "                time, value = line.strip().split()\n",
    "                #time_arr.append(np.float32(time))\n",
    "                valu_arr.append(np.float32(value))\n",
    "\n",
    "        trace = np.array(valu_arr, dtype=np.float32)\n",
    "\n",
    "        if self.cache: \n",
    "            self.cached_traces[fname] = trace\n",
    "            self.trace_list.append(trace)\n",
    "\n",
    "        return trace\n",
    "    \n",
    "    def process_label(self, label): return label\n",
    "\n",
    "    def cache_all(self):\n",
    "        assert self.cache == True\n",
    "\n",
    "        print(\"Caching all traces\")\n",
    "        for fname, fpath, label in self.file_list:\n",
    "            self.load_trace(fname, fpath)\n",
    "        print(\"DONE Caching all traces\")\n",
    "\n",
    "class TraceDatasetBW(TraceDataset):\n",
    "    def __init__(self, file_list, bit_select, cache=True):\n",
    "        self.bit_mask = 1 << bit_select\n",
    "        super().__init__(file_list, cache=cache)\n",
    "\n",
    "    def process_label(self, label):\n",
    "        return 1 if label & self.bit_mask else 0\n",
    "\n",
    "class TraceDatasetBuilder:\n",
    "    def __init__(self, adc_bitwidth=8, cache=True):\n",
    "        self.file_list        = []\n",
    "        self.cache = cache\n",
    "        self.adc_bits = adc_bitwidth\n",
    "\n",
    "        self.dataset = None\n",
    "        self.dataloader = None\n",
    "        self.datasets = []\n",
    "        self.dataloaders = []\n",
    "\n",
    "    def add_files(self, directory, format, label_group):\n",
    "        ''' Builds list of powertrace files\n",
    "        Inputs:\n",
    "            directory   : folder to search for files\n",
    "            format      : regular expression to match filenames\n",
    "            label_index : group index for digital output label corresponding to trace\n",
    "        Outputs:\n",
    "            list        : [(file_name, file_path, label) ... ]\n",
    "        '''\n",
    "        format = re.compile(format)\n",
    "        fnames = os.listdir(directory)\n",
    "\n",
    "        for fname in fnames:\n",
    "            if match := format.match(fname):\n",
    "                fpath = os.path.join(directory, fname)\n",
    "                dvalue = int(match.groups()[label_group])\n",
    "\n",
    "                self.file_list.append((fname, fpath, dvalue))\n",
    "\n",
    "    def build(self):\n",
    "        self.dataset = TraceDataset(self.file_list, cache=self.cache)\n",
    "        for b in range(self.adc_bits):\n",
    "            self.datasets.append(TraceDatasetBW(self.file_list, b, cache=self.cache))\n",
    "\n",
    "        if self.cache:\n",
    "            self.dataset.cache_all()\n",
    "\n",
    "    def build_dataloaders(self, **kwargs): # batch_size=256, shuffle=True\n",
    "        self.dataloader = DataLoader(self.dataset, **kwargs)\n",
    "        self.dataloaders = [DataLoader(dataset, **kwargs) for dataset in self.datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching all traces\n",
      "DONE Caching all traces\n"
     ]
    }
   ],
   "source": [
    "# Create dataloaders\n",
    "pwd = os.getcwd()\n",
    "# print(pwd)\n",
    "# proj_dir = os.path.dirname(os.path.dirname(pwd))\n",
    "# print(proj_dir)\n",
    "# data_dir = os.path.join(pwd, 'analog', 'outfiles')\n",
    "\n",
    "builder  = TraceDatasetBuilder(adc_bitwidth=8, cache=True)\n",
    "builder.add_files(os.path.join(pwd, 'sky_Dec_18_2151'), \"sky_d(\\\\d+)_.*\\\\.txt\", 0)\n",
    "builder.build()\n",
    "builder.build_dataloaders(batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup for ResNet\n",
    "Section where the initial imports and variables for ResNet is set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet101 code\n",
    "# Necessary imports\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "from torchvision.models import resnet101, ResNet101_Weights\n",
    "import numpy as np\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing CUDA version\n",
    "Section where we desginate the most updated CUDA version for current GPU.\n",
    "\n",
    "Implementation in progress, but is a lot of unnecessary work; will do if CPU training speeds are unformidable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training CNNs - ResNet101\n",
    "Using pretrained ResNet101, we train each CNN until all of them reaches an accuracy of 1.\n",
    "\n",
    "I'm not sure if aiming for an accuracy of 1 is beneficial, as it is just overfitting the model to the training data. A more realistic value may be 0.99, but will set it to 1 for the current simulated environment.\n",
    "\n",
    "The training function automatically reduces the learning rate used in Adam based on target accuracy. Currently testing different values and decrease rates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installed CUDA version: None\n",
      "Starting training for \"cnn_7\"...\n",
      "No GPU found, running training on CPU...\n",
      "Recheck CUDA version and if your GPU supports it.\n",
      "Checkpoint loaded. Resuming from epoch 9\n",
      "Previous reached accuracy: 1.0\n",
      "Skipping training for \"cnn_7\", already reached accuracy of 1.\n",
      "\n",
      "\n",
      "Starting training for \"cnn_6\"...\n",
      "No GPU found, running training on CPU...\n",
      "Recheck CUDA version and if your GPU supports it.\n",
      "Checkpoint loaded. Resuming from epoch 18\n",
      "Previous reached accuracy: 1.0\n",
      "Skipping training for \"cnn_6\", already reached accuracy of 1.\n",
      "\n",
      "\n",
      "Starting training for \"cnn_5\"...\n",
      "No GPU found, running training on CPU...\n",
      "Recheck CUDA version and if your GPU supports it.\n",
      "Checkpoint loaded. Resuming from epoch 26\n",
      "Previous reached accuracy: 1.0\n",
      "Skipping training for \"cnn_5\", already reached accuracy of 1.\n",
      "\n",
      "\n",
      "Starting training for \"cnn_4\"...\n",
      "No GPU found, running training on CPU...\n",
      "Recheck CUDA version and if your GPU supports it.\n",
      "Checkpoint loaded. Resuming from epoch 51\n",
      "Previous reached accuracy: 1.0\n",
      "Skipping training for \"cnn_4\", already reached accuracy of 1.\n",
      "\n",
      "\n",
      "Starting training for \"cnn_3\"...\n",
      "No GPU found, running training on CPU...\n",
      "Recheck CUDA version and if your GPU supports it.\n",
      "Checkpoint loaded. Resuming from epoch 167\n",
      "Previous reached accuracy: 0.97265625\n",
      "Updated target accuracy: 0.99\n",
      "Updated learning rate: 2.5e-05\n",
      "TRAINING: cnn[3], Epoch 168, Loss: 0.0791587308049202\n",
      "TRAINING: cnn[3], Epoch 168, Accuracy: 0.97265625\n",
      "Checkpoint saved for epoch 168\n",
      "TRAINING: cnn[3], Epoch 169, Loss: 0.08471904695034027\n",
      "TRAINING: cnn[3], Epoch 169, Accuracy: 0.98046875\n",
      "Checkpoint saved for epoch 169\n",
      "TRAINING: cnn[3], Epoch 170, Loss: 0.0899733230471611\n",
      "TRAINING: cnn[3], Epoch 170, Accuracy: 0.96484375\n",
      "Checkpoint saved for epoch 170\n",
      "TRAINING: cnn[3], Epoch 171, Loss: 0.052087850868701935\n",
      "TRAINING: cnn[3], Epoch 171, Accuracy: 0.98046875\n",
      "Checkpoint saved for epoch 171\n",
      "TRAINING: cnn[3], Epoch 172, Loss: 0.0677809789776802\n",
      "TRAINING: cnn[3], Epoch 172, Accuracy: 0.97265625\n",
      "Checkpoint saved for epoch 172\n",
      "TRAINING: cnn[3], Epoch 173, Loss: 0.06806886196136475\n",
      "TRAINING: cnn[3], Epoch 173, Accuracy: 0.9765625\n",
      "Checkpoint saved for epoch 173\n",
      "TRAINING: cnn[3], Epoch 174, Loss: 0.06963865458965302\n",
      "TRAINING: cnn[3], Epoch 174, Accuracy: 0.97265625\n",
      "Checkpoint saved for epoch 174\n",
      "TRAINING: cnn[3], Epoch 175, Loss: 0.05128616467118263\n",
      "TRAINING: cnn[3], Epoch 175, Accuracy: 0.97265625\n",
      "Checkpoint saved for epoch 175\n",
      "TRAINING: cnn[3], Epoch 176, Loss: 0.05391066148877144\n",
      "TRAINING: cnn[3], Epoch 176, Accuracy: 0.984375\n",
      "Checkpoint saved for epoch 176\n",
      "TRAINING: cnn[3], Epoch 177, Loss: 0.043430402874946594\n",
      "TRAINING: cnn[3], Epoch 177, Accuracy: 0.984375\n",
      "Checkpoint saved for epoch 177\n",
      "TRAINING: cnn[3], Epoch 178, Loss: 0.047839902341365814\n",
      "TRAINING: cnn[3], Epoch 178, Accuracy: 0.984375\n",
      "Checkpoint saved for epoch 178\n",
      "TRAINING: cnn[3], Epoch 179, Loss: 0.0470123291015625\n",
      "TRAINING: cnn[3], Epoch 179, Accuracy: 0.984375\n",
      "Checkpoint saved for epoch 179\n",
      "TRAINING: cnn[3], Epoch 180, Loss: 0.03333212435245514\n",
      "TRAINING: cnn[3], Epoch 180, Accuracy: 0.984375\n",
      "Checkpoint saved for epoch 180\n",
      "TRAINING: cnn[3], Epoch 181, Loss: 0.04432392120361328\n",
      "TRAINING: cnn[3], Epoch 181, Accuracy: 0.984375\n",
      "Checkpoint saved for epoch 181\n",
      "TRAINING: cnn[3], Epoch 182, Loss: 0.04612884670495987\n",
      "TRAINING: cnn[3], Epoch 182, Accuracy: 0.98046875\n",
      "Checkpoint saved for epoch 182\n",
      "TRAINING: cnn[3], Epoch 183, Loss: 0.03446768596768379\n",
      "TRAINING: cnn[3], Epoch 183, Accuracy: 0.98828125\n",
      "Checkpoint saved for epoch 183\n",
      "TRAINING: cnn[3], Epoch 184, Loss: 0.034435078501701355\n",
      "TRAINING: cnn[3], Epoch 184, Accuracy: 0.9921875\n",
      "Checkpoint saved for epoch 184\n",
      "Reached target accuracy 0.99\n",
      "New target accuracy 0.995\n",
      "Updating learning rate FROM: 2.5e-05, TO: 1.25e-05\n",
      "TRAINING: cnn[3], Epoch 185, Loss: 0.05542469024658203\n",
      "TRAINING: cnn[3], Epoch 185, Accuracy: 0.98046875\n",
      "Checkpoint saved for epoch 185\n",
      "TRAINING: cnn[3], Epoch 186, Loss: 0.04737524688243866\n",
      "TRAINING: cnn[3], Epoch 186, Accuracy: 0.984375\n",
      "Checkpoint saved for epoch 186\n",
      "TRAINING: cnn[3], Epoch 187, Loss: 0.030140450224280357\n",
      "TRAINING: cnn[3], Epoch 187, Accuracy: 0.98046875\n",
      "Checkpoint saved for epoch 187\n",
      "TRAINING: cnn[3], Epoch 188, Loss: 0.09020961821079254\n",
      "TRAINING: cnn[3], Epoch 188, Accuracy: 0.96875\n",
      "Checkpoint saved for epoch 188\n",
      "TRAINING: cnn[3], Epoch 189, Loss: 0.07526921480894089\n",
      "TRAINING: cnn[3], Epoch 189, Accuracy: 0.97265625\n",
      "Checkpoint saved for epoch 189\n",
      "TRAINING: cnn[3], Epoch 190, Loss: 0.04149562865495682\n",
      "TRAINING: cnn[3], Epoch 190, Accuracy: 0.98828125\n",
      "Checkpoint saved for epoch 190\n",
      "TRAINING: cnn[3], Epoch 191, Loss: 0.04927176237106323\n",
      "TRAINING: cnn[3], Epoch 191, Accuracy: 0.98046875\n",
      "Checkpoint saved for epoch 191\n",
      "TRAINING: cnn[3], Epoch 192, Loss: 0.027132034301757812\n",
      "TRAINING: cnn[3], Epoch 192, Accuracy: 0.98828125\n",
      "Checkpoint saved for epoch 192\n",
      "TRAINING: cnn[3], Epoch 193, Loss: 0.040601566433906555\n",
      "TRAINING: cnn[3], Epoch 193, Accuracy: 0.9765625\n",
      "Checkpoint saved for epoch 193\n",
      "TRAINING: cnn[3], Epoch 194, Loss: 0.05601370334625244\n",
      "TRAINING: cnn[3], Epoch 194, Accuracy: 0.9765625\n",
      "Checkpoint saved for epoch 194\n",
      "TRAINING: cnn[3], Epoch 195, Loss: 0.05537042021751404\n",
      "TRAINING: cnn[3], Epoch 195, Accuracy: 0.9765625\n",
      "Checkpoint saved for epoch 195\n",
      "TRAINING: cnn[3], Epoch 196, Loss: 0.03056027740240097\n",
      "TRAINING: cnn[3], Epoch 196, Accuracy: 0.98828125\n",
      "Checkpoint saved for epoch 196\n",
      "TRAINING: cnn[3], Epoch 197, Loss: 0.08272221684455872\n",
      "TRAINING: cnn[3], Epoch 197, Accuracy: 0.97265625\n",
      "Checkpoint saved for epoch 197\n",
      "TRAINING: cnn[3], Epoch 198, Loss: 0.06555967777967453\n",
      "TRAINING: cnn[3], Epoch 198, Accuracy: 0.9609375\n",
      "Checkpoint saved for epoch 198\n",
      "TRAINING: cnn[3], Epoch 199, Loss: 0.03787647560238838\n",
      "TRAINING: cnn[3], Epoch 199, Accuracy: 0.9921875\n",
      "Checkpoint saved for epoch 199\n",
      "TRAINING: cnn[3], Epoch 200, Loss: 0.03566046431660652\n",
      "TRAINING: cnn[3], Epoch 200, Accuracy: 0.984375\n",
      "Checkpoint saved for epoch 200\n",
      "TRAINING: cnn[3], Epoch 201, Loss: 0.04249608516693115\n",
      "TRAINING: cnn[3], Epoch 201, Accuracy: 0.98046875\n",
      "Checkpoint saved for epoch 201\n",
      "TRAINING: cnn[3], Epoch 202, Loss: 0.05182020738720894\n",
      "TRAINING: cnn[3], Epoch 202, Accuracy: 0.98046875\n",
      "Checkpoint saved for epoch 202\n",
      "TRAINING: cnn[3], Epoch 203, Loss: 0.030084999278187752\n",
      "TRAINING: cnn[3], Epoch 203, Accuracy: 0.9921875\n",
      "Checkpoint saved for epoch 203\n",
      "TRAINING: cnn[3], Epoch 204, Loss: 0.04228849709033966\n",
      "TRAINING: cnn[3], Epoch 204, Accuracy: 0.984375\n",
      "Checkpoint saved for epoch 204\n",
      "TRAINING: cnn[3], Epoch 205, Loss: 0.04081026092171669\n",
      "TRAINING: cnn[3], Epoch 205, Accuracy: 0.98828125\n",
      "Checkpoint saved for epoch 205\n",
      "TRAINING: cnn[3], Epoch 206, Loss: 0.02390015684068203\n",
      "TRAINING: cnn[3], Epoch 206, Accuracy: 0.9921875\n",
      "Checkpoint saved for epoch 206\n",
      "TRAINING: cnn[3], Epoch 207, Loss: 0.04000938683748245\n",
      "TRAINING: cnn[3], Epoch 207, Accuracy: 0.98828125\n",
      "Checkpoint saved for epoch 207\n",
      "TRAINING: cnn[3], Epoch 208, Loss: 0.018527504056692123\n",
      "TRAINING: cnn[3], Epoch 208, Accuracy: 0.9921875\n",
      "Checkpoint saved for epoch 208\n",
      "TRAINING: cnn[3], Epoch 209, Loss: 0.0888608917593956\n",
      "TRAINING: cnn[3], Epoch 209, Accuracy: 0.96875\n",
      "Checkpoint saved for epoch 209\n",
      "TRAINING: cnn[3], Epoch 210, Loss: 0.06904765218496323\n",
      "TRAINING: cnn[3], Epoch 210, Accuracy: 0.9765625\n",
      "Checkpoint saved for epoch 210\n",
      "TRAINING: cnn[3], Epoch 211, Loss: 0.04031256586313248\n",
      "TRAINING: cnn[3], Epoch 211, Accuracy: 0.984375\n",
      "Checkpoint saved for epoch 211\n"
     ]
    }
   ],
   "source": [
    "cnns = []\n",
    "dataloaders = builder.dataloaders \n",
    "timestamp   = datetime.datetime.now().strftime('%Y%m%d_%H%M')\n",
    "\n",
    "'''\n",
    "plt.ion()\n",
    "figs, axs = plt.subplots(2)\n",
    "axs[0].set_title(\"Loss\")\n",
    "axs[1].set_title(\"Accuracy\")\n",
    "'''\n",
    "\n",
    "print(f\"Installed CUDA version: {torch.version.cuda}\")\n",
    "\n",
    "# Create CNN per dataset\n",
    "for i in range(7,-1,-1):\n",
    "    print(f\"Starting training for \\\"cnn_{i}\\\"...\")\n",
    "    # Model: ResNet101, pretrained=true, using ResNet101_Weights.DEFAULT for up-to-date values\n",
    "    cnn = resnet101(weights=ResNet101_Weights.DEFAULT)\n",
    "    cnn.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "    cnn.fc = nn.Linear(cnn.fc.in_features, 2)\n",
    "    # Loss function: not specified in paper, used Cross Entropy Loss\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Optimizer: not specified in paper, used Adam\n",
    "    # Target accuracies to update the learning rate\n",
    "    # Use different values if needed\n",
    "    target_acc = [0.90, 0.95, 0.99, 0.995, 1.0]\n",
    "    target_acc_index = 0\n",
    "    learning_rate = 1e-4\n",
    "    optimizer = optim.Adam(cnn.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Parameters for training CNN\n",
    "    num_epochs = 1000\n",
    "    max_grad_norm = 1.0  # Gradient clipping threshold\n",
    "    learning_rate = 1e-4  # Reduced learning rate for stability, inital value = 1e-4\n",
    "    '''\n",
    "    # Paramters for plot, may erase if not used\n",
    "    loss_arr = []  # Array used to store loss values over epoches\n",
    "    acc_arr  = []  # Array used to store accuracy values over epoches\n",
    "    loss_g = None\n",
    "    acc_g  = None\n",
    "    '''\n",
    "\n",
    "    # Append CNN to cnns array\n",
    "    cnns.append(cnn)\n",
    "\n",
    "    # Create checkpoint to save progress\n",
    "    checkpoint_path = f\"resnet101_checkpoint_{i}.pth\"\n",
    "    start_epoch = 0\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(\"GPU found, running training on GPU...\")\n",
    "        device = torch.device(\"cuda\")\n",
    "        cnn = cnn.to(device)\n",
    "    else:\n",
    "        print(\"No GPU found, running training on CPU...\")\n",
    "        print(\"Recheck CUDA version and if your GPU supports it.\")\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    # Try to load .pth file\n",
    "    # NEED TO ADD FUNCTIONALITY TO CHECK INTEGRITY OF .pth FILE\n",
    "    try:\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=True)\n",
    "        cnn.load_state_dict(checkpoint['cnn_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        print(f\"Checkpoint loaded. Resuming from epoch {start_epoch}\")\n",
    "        reached_target_acc = checkpoint['reached_acc']\n",
    "        print(f\"Previous reached accuracy: {reached_target_acc}\")\n",
    "        if reached_target_acc == 1:\n",
    "            print(f\"Skipping training for \\\"cnn_{i}\\\", already reached accuracy of 1.\\n\\n\")\n",
    "            continue\n",
    "        while target_acc_index < len(target_acc) - 1 and target_acc[target_acc_index] < reached_target_acc:\n",
    "            target_acc_index += 1\n",
    "            learning_rate /= 2\n",
    "        print(f\"Updated target accuracy: {target_acc[target_acc_index]}\")\n",
    "        print(f\"Updated learning rate: {learning_rate}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"No checkpoint found for \\\"cnn_{i}\\\". Starting from scratch.\")\n",
    "\n",
    "    # Start training\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        correct = 0\n",
    "        cnn.train()\n",
    "\n",
    "        for inputs, labels in dataloaders[i]:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            # Add dimensions for channels and width\n",
    "            inputs = inputs.unsqueeze(1).unsqueeze(-1)\n",
    "            optimizer.zero_grad()\n",
    "            output = cnn(inputs)\n",
    "            # Check for NaN in outputs\n",
    "            if torch.isnan(output).any():\n",
    "                print(\"NaN detected in cnn outputs.\")\n",
    "                break\n",
    "\n",
    "            loss = criterion(output, labels)\n",
    "            # Check for NaN in loss\n",
    "            if torch.isnan(loss):\n",
    "                print(\"NaN detected in loss. Stopping training.\")\n",
    "                break\n",
    "            # print(f\"Loss: {loss.item()}\")\n",
    "            loss.backward()\n",
    "\n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(cnn.parameters(), max_grad_norm)\n",
    "            optimizer.step()\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            correct += (predicted == labels).sum()\n",
    "        \n",
    "        accuracy = correct / 256\n",
    "        '''\n",
    "        acc_arr.append(accuracy)\n",
    "        loss_arr.append(loss.item())\n",
    "        '''\n",
    "        # Change rate of update for printing accuracy accordingly\n",
    "        if (epoch + 1) % 1 == 0:\n",
    "            print(f'TRAINING: cnn[{i}], Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "            print(f'TRAINING: cnn[{i}], Epoch {epoch+1}, Accuracy: {accuracy}')\n",
    "        '''\n",
    "        if epoch % 50 == 0: \n",
    "            if loss_g: loss_g.remove()\n",
    "            if acc_g:  acc_g.remove()\n",
    "            loss_g = axs[0].plot(loss_arr, color='lightgray', linestyle='dotted')[0]\n",
    "            loss_a = axs[1].plot(acc_arr,  color='lightgray', linestyle='dotted')[0]\n",
    "            plt.pause(0.01)\n",
    "        '''\n",
    "\n",
    "        # Save checkpoint\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'cnn_state_dict': cnn.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'reached_acc': accuracy\n",
    "        }, checkpoint_path)\n",
    "        print(f\"Checkpoint saved for epoch {epoch + 1}\")\n",
    "\n",
    "        # Check oscillation\n",
    "        \n",
    "\n",
    "        # If training reached accuracy of 1, stop training\n",
    "        if accuracy == 1:\n",
    "            print(f\"Reached accuracy of 1. Stopping training for \\\"cnn_{i}\\\".\\n\")\n",
    "            break\n",
    "        # Update learning rate if accuracy reaches target value\n",
    "        # Reducing stepsize accordingly so the optimizer does not overshoot\n",
    "        elif target_acc[target_acc_index] < accuracy and target_acc_index != len(target_acc) - 1:\n",
    "            updated = False\n",
    "            temp = learning_rate\n",
    "            while target_acc_index <= len(target_acc) - 1 and target_acc[target_acc_index] < accuracy:\n",
    "                target_acc_index += 1\n",
    "                learning_rate = learning_rate / 2\n",
    "                updated = True\n",
    "            if updated:\n",
    "                print(f\"Reached target accuracy {target_acc[target_acc_index-1]}\")\n",
    "                print(f\"New target accuracy {target_acc[target_acc_index]}\")\n",
    "                print(f\"Updating learning rate FROM: {temp}, TO: {learning_rate}\")\n",
    "\n",
    "'''\n",
    "    label = f'cnn[{i}]'\n",
    "    axs[0].plot(loss_arr, label=label)\n",
    "    axs[1].plot(acc_arr,  label=label)\n",
    "    axs[0].legend()\n",
    "    axs[1].legend()\n",
    "    plt.pause(0.01)\n",
    "\n",
    "plt.pause(60*10)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the CNNs\n",
    "\n",
    "Using the resulting CNNs saved in the .pth files, we test each CNNs using the provided power traces.\n",
    "\n",
    "Currently the testing data is a subset of the training data. In the future, if we can generate more data, we will be able to use separate datasets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run evaluation using testing data\n",
    "# CURRENTLY USING TRAINING DATA TO TEST DATA: use separate dataset in the future\n",
    "for i in range(7,-1,-1):\n",
    "    try:\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=True)\n",
    "        cnn.load_state_dict(checkpoint['cnn_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        print(f\"Checkpoint loaded. Resuming from epoch {start_epoch}\")\n",
    "        reached_target_acc = checkpoint['reached_acc']\n",
    "        print(f\"Previous reached accuracy: {reached_target_acc}\")\n",
    "        if reached_target_acc != 1:\n",
    "            print(f\"cnn_{i}\\\" did not reach accuracy of 1, skipping evaluation.\\n\\n\")\n",
    "            continue\n",
    "    except FileNotFoundError:\n",
    "        print(f\"No checkpoint found for \\\"cnn_{i}\\\". Starting from scratch.\")\n",
    "\n",
    "    cnns[i].eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloaders[i]:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            # Add dimensions for channels and width\n",
    "            inputs = inputs.unsqueeze(1).unsqueeze(-1)\n",
    "            outputs = cnns[i](inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Accuracy: {100 * correct / total:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
